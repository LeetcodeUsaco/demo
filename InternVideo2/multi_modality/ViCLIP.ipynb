{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c23d3d6a",
   "metadata": {},
   "source": [
    "## download ViCILP weights and put its pth file in viclip folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f58b44c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/qing/PycharmProjects/InternVideo/Data/InternVid\n"
     ]
    }
   ],
   "source": [
    "!pip install -q --upgrade setuptools==69.5.1\n",
    "\n",
    "%cd ../../Data/InternVid\n",
    "!pip install -q ftfy einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a46df22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from viclip import get_viclip, retrieve_text, _frame_from_video\n",
    "from iv2_utils.iv2 import *\n",
    "\n",
    "def listfile(path):\n",
    "    return [os.path.join(path, x) for x in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61072f2",
   "metadata": {},
   "source": [
    "$$\\Large \\textbf{Adding noise to video + Splitting Video to 8-bit Windows}$$\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aeaf4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from PIL import Image, ImageSequence\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import shutil\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def split_video_to_mp4(video_path, output_dir, window_size=4):\n",
    "    if output_dir in os.listdir('.'):\n",
    "        shutil.rmtree(output_dir)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    if video_path.endswith('.gif'):\n",
    "        gif = Image.open(video_path)\n",
    "        frames = [frame.copy() for frame in ImageSequence.Iterator(gif)]\n",
    "        total_frames = len(frames)\n",
    "\n",
    "        width, height = frames[0].size\n",
    "        duration = gif.info['duration']\n",
    "        fps = 1000 / duration\n",
    "    else:\n",
    "        video = cv2.VideoCapture(video_path)\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        frames = []\n",
    "        success, frame = video.read()\n",
    "        while success:\n",
    "            frames.append(frame)\n",
    "            success, frame = video.read()\n",
    "        video.release()\n",
    "\n",
    "    for i in range(total_frames - window_size + 1):\n",
    "        output_path = os.path.join(output_dir, f'{i + 1}.mp4')\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "        for frame in frames[i:i + window_size]:\n",
    "            if isinstance(frame, Image.Image):\n",
    "                frame_rgb = frame.convert('RGB')\n",
    "                frame_array = np.array(frame_rgb)\n",
    "                frame_bgr = cv2.cvtColor(frame_array, cv2.COLOR_RGB2BGR)\n",
    "            else:\n",
    "                frame_bgr = frame\n",
    "            out.write(frame_bgr)\n",
    "\n",
    "        out.release()\n",
    "\n",
    "def load_basketball(basketball_path, size):\n",
    "    basketball = Image.open(basketball_path)\n",
    "    basketball = basketball.resize((size, size), Image.LANCZOS)\n",
    "    return basketball\n",
    "\n",
    "def rotate_basketball(basketball):\n",
    "    random_angle = np.random.randint(0, 360)\n",
    "    return basketball.rotate(random_angle, expand=True)\n",
    "\n",
    "def add_basketball_to_frame(frame, basketball):\n",
    "    frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    basketball_rotated = rotate_basketball(basketball)\n",
    "\n",
    "    frame_width, frame_height = frame_pil.size\n",
    "    basketball_width, basketball_height = basketball_rotated.size\n",
    "\n",
    "    max_x = frame_width - basketball_width\n",
    "    max_y = frame_height - basketball_height\n",
    "    rand_x = np.random.randint(0, max_x)\n",
    "    rand_y = np.random.randint(0, max_y)\n",
    "\n",
    "    frame_pil.paste(basketball_rotated, (rand_x, rand_y), basketball_rotated)\n",
    "    return cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def add_noise(input_video_path, output_video_path, basketball_path, basketball_size):\n",
    "    basketball = load_basketball(basketball_path, basketball_size)\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_with_basketball = add_basketball_to_frame(frame, basketball)\n",
    "\n",
    "        out.write(frame_with_basketball)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    #cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaadbf8",
   "metadata": {},
   "source": [
    "$$\\Large \\textbf{Loading the ViCLIP Model}$$\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca05af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qing/PycharmProjects/InternVideo/Data/InternVid/viclip/viclip.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(pretrain, map_location='cpu')['model']\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = './viclip.pth'\n",
    "model_cfgs = {\n",
    "    'viclip-l-internvid-10m-flt': {\n",
    "        'size': 'l',\n",
    "        'pretrained': checkpoint_path,\n",
    "    },\n",
    "    'viclip-l-internvid-200m': {\n",
    "        'size': 'l',\n",
    "        'pretrained': checkpoint_path,\n",
    "    },\n",
    "    'viclip-b-internvid-10m-flt': {\n",
    "        'size': 'b',\n",
    "        'pretrained': checkpoint_path,\n",
    "    },\n",
    "    'viclip-b-internvid-200m': {\n",
    "        'size': 'b',\n",
    "        'pretrained': checkpoint_path,\n",
    "    },\n",
    "}\n",
    "cfg = model_cfgs['viclip-l-internvid-10m-flt']\n",
    "model_l = get_viclip(cfg['size'], cfg['pretrained'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4510f9a",
   "metadata": {},
   "source": [
    "$$\\Large \\textbf{Adding Backflip Videos}$$\n",
    "\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcc9677",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'backflip' in os.listdir('.'):\n",
    "    shutil.rmtree('backflip')\n",
    "\n",
    "os.system('wget -q \\\"https://s3.amazonaws.com/kinetics/600/val/backflip (human).tar.gz\\\"')\n",
    "shutil.unpack_archive('backflip (human).tar.gz', 'backflip')\n",
    "\n",
    "j = 1\n",
    "for i in sorted(os.listdir('backflip')):\n",
    "    os.rename(os.path.join('backflip', i), os.path.join('backflip', f'{j}.mp4'))\n",
    "    j += 1\n",
    "    \n",
    "backflip_files = os.listdir('backflip')\n",
    "backflip_files.sort(key=lambda x: int(x.split('.')[0]))\n",
    "backflip_files = [os.path.join('backflip', file) for file in backflip_files]\n",
    "print(backflip_files[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59611816",
   "metadata": {},
   "source": [
    "**Adding Noise to Videos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5eca4d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if 'aug1' in os.listdir('.'):\n",
    "    shutil.rmtree('aug1')\n",
    "if 'aug2' in os.listdir('.'):\n",
    "    shutil.rmtree('aug2')\n",
    "\n",
    "def get_dim(file_path):\n",
    "    vid = cv2.VideoCapture(file_path)\n",
    "    height = vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    width = vid.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    return height, width\n",
    "\n",
    "os.mkdir('aug1')\n",
    "os.mkdir('aug2')\n",
    "for backflip in tqdm(backflip_files):\n",
    "    height, width = get_dim(backflip)\n",
    "    add_noise(backflip, os.path.join('aug1', backflip.split('/')[1]), 'Storage/cruise.png', int(min(height, width) / 3))\n",
    "\n",
    "for aug1 in tqdm([os.path.join('aug1',x) for x in os.listdir('aug1')]):\n",
    "    height, width = get_dim(aug1)\n",
    "    add_noise(aug1, os.path.join('aug2', aug1.split('/')[1]), 'Storage/cruise.png', int(min(height, width) / 3))\n",
    "\n",
    "shutil.rmtree('aug1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82748aa9-275e-4a9d-83a3-c22a416febb7",
   "metadata": {},
   "source": [
    "$$\\Large \\textbf{Evaluation on K400}$$\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7580d2d1-5889-440b-a006-ccaa4267c8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label   youtube_id\n",
      "0  abseiling  0wR5jVB-WPk\n",
      "1  abseiling  3caPS4FHFF8\n",
      "2  abseiling  3yaoNwz99xM\n",
      "3  abseiling  6IbvOJxXnOo\n",
      "4  abseiling  6_4kjPiQr7w\n",
      "\n",
      "['-j3eNzQR-EI_000064_000074.mp4', '-C-PvafuvFE_000068_000078.mp4', '0yNXOIqJLtA_000012_000022.mp4', '13Ub1MDkiHc_000014_000024.mp4', '-IlFdaVdEyU_000001_000011.mp4']\n",
      "Removed 0 Videos!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "val_data = pd.read_csv('../../InternVideo2/multi_modality/k600/val.csv').iloc[:,0:2]\n",
    "videos = os.listdir('../../InternVideo2/multi_modality/k600/part_0')\n",
    "\n",
    "print(val_data.head())\n",
    "print()\n",
    "print(videos[-5:])\n",
    "\n",
    "id_label_map = {}\n",
    "for row in range(len(val_data)):\n",
    "    id_label_map[val_data.iloc[row]['youtube_id']] = val_data.iloc[row]['label']\n",
    "\n",
    "remove_points = len(videos) - 500\n",
    "sampled_points = np.random.choice(videos, remove_points, replace=False)\n",
    "classes = val_data['label'].unique()\n",
    "for i in sampled_points:\n",
    "    os.remove(f'../../InternVideo2/multi_modality/k600/part_0/{i}')\n",
    "print(f\"Removed {remove_points} Videos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1605ed6b-3786-450b-9e61-01271ad639b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 Completed\n",
      "-------------------------\n",
      "Correct: playing harmonica\n",
      "-------------------------\n",
      "Predictions -------------\n",
      "0.2789 | playing harmonica\n",
      "0.2136 | playing flute\n",
      "0.2064 | playing recorder\n",
      "0.2021 | brushing teeth\n",
      "0.2020 | playing xylophone\n",
      "-------------------------\n",
      "Top 1: 0.548\n",
      "Top 5: 0.83\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "top1 = 0\n",
    "top5 = 0\n",
    "total = 0\n",
    "collect_data = []\n",
    "for check in videos:\n",
    "    video = cv2.VideoCapture(f'../../InternVideo2/multi_modality/k600/part_0/{check}')\n",
    "    frames = [x for x in _frame_from_video(video)]\n",
    "    \n",
    "    video_label = id_label_map[check[:11]]\n",
    "    \n",
    "    texts, probs = retrieve_text(frames, classes, models=model_l, topk=5, device=\"cpu\")\n",
    "    collect_data.append((texts, probs))\n",
    "    clear_output(wait=True)\n",
    "    if texts[0] == video_label:\n",
    "        top1 += 1\n",
    "    if video_label in texts:\n",
    "        top5 += 1\n",
    "    total += 1\n",
    "    print(f\"{total}/500 Completed\")\n",
    "    print('-'*25)\n",
    "    print(\"Correct:\", video_label)\n",
    "    print('-'*25)\n",
    "    print('Predictions ' + '-'*13)\n",
    "    for i, v in zip(texts, probs):\n",
    "        print(f'{v:.4f}', '|', i)\n",
    "    print('-'*25)\n",
    "    print(\"Top 1:\",top1/total)\n",
    "    print(\"Top 5:\", top5/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5c9297-5712-44f4-b1da-59e82cdfd7d4",
   "metadata": {},
   "source": [
    "$$\\Large \\textbf{Evaluation on GIF100}$$\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "508c416e-be46-4311-89ec-3083a246b161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 videos!\n"
     ]
    }
   ],
   "source": [
    "videos = pickle_read('../../../photography-model/rustyjar/STOCK100.pkl')\n",
    "print(\"Loaded\",len(videos),\"videos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57bb696d-239e-438d-9d85-bd80af830bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GIF100/5.mp4',\n",
       " 'A person splashes into the pool.',\n",
       " [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "896665f0-7b72-48e4-ba73-894502438647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A small kid falls down onto the ground.': tensor([[-4.5776e-02, -2.1813e-02, -2.0643e-03,  5.7868e-02,  1.1160e-02,\n",
       "          -1.6745e-02,  3.5187e-02, -4.3393e-03,  3.3565e-03, -1.8007e-02,\n",
       "          -4.3136e-02,  1.9561e-02,  1.3579e-02,  2.2094e-03, -1.5398e-02,\n",
       "          -1.3152e-03,  1.8768e-02,  2.0182e-02, -5.9828e-02, -2.0360e-02,\n",
       "           7.3737e-03,  2.1527e-02, -1.5426e-02,  1.8080e-02,  7.5934e-03,\n",
       "          -3.0730e-02, -3.8834e-02,  2.0356e-03,  1.3019e-02,  9.4537e-03,\n",
       "           2.0870e-03,  4.2311e-02,  1.6326e-03, -8.5308e-03,  3.2212e-02,\n",
       "          -2.4307e-02, -9.1623e-03,  1.5416e-02, -3.0801e-02, -1.2381e-02,\n",
       "          -3.8146e-02, -2.8381e-02,  3.3975e-02,  1.2653e-02, -3.5661e-03,\n",
       "           1.4811e-02,  2.6234e-02,  2.4688e-02,  2.0408e-02, -1.6954e-02,\n",
       "           2.5903e-02, -4.1720e-02,  4.5704e-03,  4.4504e-03, -9.9096e-03,\n",
       "           1.8941e-02,  4.2951e-02, -1.7330e-03,  3.6770e-02,  9.0733e-03,\n",
       "           1.4584e-02,  1.2002e-02, -2.2910e-02,  2.0180e-03,  1.1438e-02,\n",
       "          -1.2453e-02,  1.1292e-02, -1.5333e-02, -4.4006e-02,  6.6791e-03,\n",
       "          -1.8657e-02, -5.2472e-03, -1.5696e-02,  2.5971e-02, -2.7242e-02,\n",
       "          -1.1973e-02,  1.3761e-02, -2.1907e-02,  1.3636e-02,  2.6914e-02,\n",
       "           1.2234e-02,  2.2394e-02,  3.9670e-02,  2.2691e-03, -1.9608e-03,\n",
       "           4.6920e-03, -3.2277e-02, -3.1629e-03, -1.1664e-02, -2.5846e-02,\n",
       "           4.1473e-02,  3.7466e-02,  5.1582e-02, -1.4182e-02, -2.7527e-02,\n",
       "          -4.3439e-02, -1.4084e-02,  1.9992e-02, -9.9443e-04,  2.6841e-02,\n",
       "           1.7348e-02, -3.1207e-02, -3.3154e-03, -1.5171e-04, -9.9560e-03,\n",
       "          -8.4566e-03,  5.7320e-02, -1.3252e-02,  1.2555e-02, -4.1829e-02,\n",
       "           3.4784e-02,  2.8874e-02, -4.8344e-04,  5.5103e-03, -3.3889e-02,\n",
       "          -7.8501e-03, -4.4201e-02, -3.2376e-02,  1.7846e-02, -1.3405e-02,\n",
       "           1.9117e-03, -5.7502e-02, -8.3956e-03, -2.2784e-02, -3.5713e-02,\n",
       "           1.5903e-02, -4.2647e-03,  2.5061e-02,  1.0793e-02, -2.1804e-02,\n",
       "          -1.8831e-02, -1.9677e-02,  2.8542e-02, -1.2718e-02, -5.6086e-02,\n",
       "          -6.1001e-03,  2.9088e-02,  2.9466e-02, -4.6339e-02, -1.9764e-02,\n",
       "           3.6626e-02, -2.3365e-02,  1.8827e-02, -5.3360e-03,  1.1864e-02,\n",
       "           5.9639e-03,  1.3487e-02, -4.1996e-02,  1.2708e-02,  8.2221e-03,\n",
       "           1.3062e-02, -5.0517e-03, -4.1720e-03, -2.8927e-03, -2.6193e-03,\n",
       "           8.5743e-03,  9.3462e-03,  1.8210e-03, -1.5047e-02, -4.0628e-02,\n",
       "          -4.9939e-03,  2.2310e-03,  1.3955e-02, -2.2616e-03,  5.1904e-03,\n",
       "          -4.9767e-05,  7.2960e-03,  7.2541e-03,  1.1394e-02,  1.6635e-02,\n",
       "           2.3650e-02, -1.7426e-03,  3.0959e-02,  2.1169e-03,  3.3947e-02,\n",
       "           3.1697e-02, -3.8787e-02, -5.4836e-02, -2.8492e-02, -1.0846e-02,\n",
       "           1.2225e-02,  1.7842e-02,  3.5608e-02, -1.9866e-02,  3.1526e-03,\n",
       "          -3.9357e-03,  8.8142e-04,  1.9305e-02, -7.2060e-03,  1.4291e-02,\n",
       "          -6.2488e-03, -2.5664e-02,  1.2786e-02,  2.8633e-03, -3.4219e-02,\n",
       "          -1.3686e-01, -4.7596e-03,  3.7603e-02, -4.8053e-03, -1.4941e-03,\n",
       "          -1.4845e-02,  4.5291e-02, -9.3556e-03,  3.8168e-02,  1.7560e-03,\n",
       "          -6.2470e-03,  4.5964e-02, -1.2363e-02,  2.1743e-02, -5.7147e-03,\n",
       "           9.0397e-03, -7.7539e-04, -9.5346e-04,  6.0718e-03,  1.3841e-02,\n",
       "          -5.1949e-03, -1.0877e-02,  9.7132e-03, -1.5226e-03,  4.2351e-03,\n",
       "           2.5324e-02, -2.0845e-02, -2.1818e-02,  2.1103e-02, -6.5129e-03,\n",
       "           5.6175e-03, -2.5503e-02, -1.6360e-02, -5.9921e-03,  1.8895e-03,\n",
       "           1.2710e-02, -2.3173e-02, -5.0154e-04,  1.3140e-02, -1.8711e-02,\n",
       "           1.2816e-02,  1.1954e-03, -5.2468e-03, -3.6704e-03,  6.6377e-03,\n",
       "           3.6557e-02,  2.8194e-02,  1.2466e-02,  1.4744e-02, -2.8750e-02,\n",
       "           1.1879e-02,  2.6933e-02, -1.0973e-02,  1.6558e-02,  1.1432e-02,\n",
       "           7.9096e-03,  2.2045e-02, -9.6801e-03, -1.6960e-02, -9.5746e-03,\n",
       "          -1.9491e-03, -5.9946e-03, -3.3400e-02, -1.2008e-03, -3.3462e-02,\n",
       "          -3.2945e-02,  2.0816e-03,  4.8920e-03,  1.3848e-02, -8.8764e-03,\n",
       "           9.6962e-03, -5.5849e-04,  1.8251e-02, -5.4424e-03,  4.1275e-03,\n",
       "           6.1977e-03,  3.6694e-02,  1.0237e-03,  1.4124e-02, -2.5936e-03,\n",
       "          -1.3860e-02, -2.4263e-02, -2.2699e-02, -3.6753e-03, -1.2286e-04,\n",
       "          -1.6400e-02,  3.5391e-03,  2.1251e-02, -3.0117e-02, -1.0932e-02,\n",
       "           2.0856e-03,  1.2465e-03,  1.1851e-02, -1.0308e-01, -3.0055e-02,\n",
       "          -4.0147e-02, -3.7227e-02, -2.1588e-02, -1.8689e-02,  6.4089e-03,\n",
       "           3.1699e-02,  1.1070e-02, -1.5222e-02,  7.8858e-03,  1.9661e-02,\n",
       "          -9.1424e-03, -8.0743e-03,  9.9621e-03,  5.3775e-03, -5.9683e-03,\n",
       "          -2.0271e-03, -6.6465e-03, -6.5191e-03,  1.7407e-02, -3.5753e-03,\n",
       "           1.2922e-02, -8.6632e-03,  9.0140e-03, -4.7311e-03,  1.9979e-02,\n",
       "           1.7414e-02, -5.6843e-01, -7.8953e-03, -1.2731e-03, -7.6623e-03,\n",
       "           3.5092e-04,  1.2964e-02,  3.8497e-02, -4.7646e-02, -1.7902e-02,\n",
       "           6.6633e-03, -1.9184e-02,  1.2466e-02, -2.2554e-03,  3.9160e-02,\n",
       "          -4.2720e-02,  9.7973e-03,  8.7071e-03,  1.2254e-02, -1.1203e-02,\n",
       "           2.0460e-02,  3.0702e-02,  9.4431e-03, -1.4011e-02, -6.4062e-03,\n",
       "           1.5837e-02,  3.4329e-02, -1.4653e-02, -6.3434e-03,  1.4627e-02,\n",
       "           4.1226e-02,  1.3429e-02,  8.4623e-02,  6.0732e-03, -2.7726e-03,\n",
       "          -1.1086e-02, -1.3129e-02,  2.2840e-02, -5.3509e-02, -4.1984e-03,\n",
       "           2.1440e-03,  1.9850e-02, -4.2356e-02,  8.0632e-04,  5.6475e-03,\n",
       "           2.7630e-02,  1.0411e-03,  3.1501e-05, -3.3081e-02, -2.1276e-02,\n",
       "          -3.7794e-02,  4.3288e-02,  4.5682e-03,  2.2072e-02,  1.7267e-02,\n",
       "           6.6709e-03,  1.4344e-02, -2.0820e-02, -9.3896e-03,  2.5590e-02,\n",
       "          -1.7123e-02, -2.9225e-03,  1.8070e-02, -1.1383e-02, -1.6552e-02,\n",
       "           1.8528e-03,  1.8842e-05, -1.8623e-02, -3.3514e-02, -2.6756e-03,\n",
       "          -1.3149e-02,  3.3852e-02, -2.6092e-02,  4.7411e-02, -5.0947e-03,\n",
       "           6.0525e-03,  1.2974e-03,  3.3684e-02, -4.5008e-02, -2.1997e-02,\n",
       "          -5.6659e-02,  2.2726e-02, -1.9779e-02, -2.3195e-02,  1.7424e-02,\n",
       "           2.1908e-03, -2.6177e-02, -1.4223e-02,  1.0731e-02,  3.9909e-02,\n",
       "           2.9745e-02,  1.3860e-02,  4.9048e-03, -3.5952e-03,  2.2435e-02,\n",
       "          -9.8543e-03, -5.8905e-03, -1.0587e-02, -6.8924e-02,  2.1362e-02,\n",
       "           5.8678e-02,  1.7859e-03, -1.2006e-02, -2.0526e-02, -1.7884e-02,\n",
       "           1.6101e-02, -2.5831e-02,  6.0073e-03, -1.7789e-02, -1.0391e-02,\n",
       "           4.1130e-03, -4.1972e-03, -4.9029e-03,  1.0042e-02, -2.3938e-02,\n",
       "           1.0581e-02, -4.4423e-03, -2.3541e-02, -8.5225e-04, -2.3424e-03,\n",
       "           6.8901e-03, -8.8460e-03,  1.4085e-03,  2.6300e-02, -1.0093e-02,\n",
       "           5.1699e-01, -9.7385e-03, -1.2847e-02,  1.6570e-02,  2.1319e-02,\n",
       "          -9.1939e-03, -1.3862e-02,  1.2427e-02, -2.4069e-02,  1.0642e-03,\n",
       "          -5.2176e-02, -2.3221e-02,  5.6016e-03, -1.2170e-02,  4.3383e-02,\n",
       "           2.6419e-02, -4.3803e-03,  2.1355e-02, -1.1124e-02,  1.8291e-02,\n",
       "           3.3718e-02,  1.4410e-02, -1.2191e-02,  1.3082e-02, -3.4640e-02,\n",
       "           1.5671e-03,  2.6715e-02,  2.6536e-02,  1.4510e-02, -1.9300e-02,\n",
       "          -1.7117e-03,  5.7572e-03, -3.8872e-02,  1.2979e-02, -1.4191e-03,\n",
       "          -2.7636e-02,  3.6937e-02, -1.4243e-02, -1.0001e-02, -7.5028e-03,\n",
       "          -1.7438e-03, -7.1827e-03,  1.9519e-02, -1.5699e-02, -1.0598e-02,\n",
       "           3.9544e-02, -4.4752e-03, -1.1640e-02,  3.5602e-02, -8.0790e-03,\n",
       "          -9.5633e-03,  2.7785e-03, -5.7081e-02, -3.1564e-03,  2.9018e-03,\n",
       "          -2.8856e-03, -2.7376e-02, -5.1952e-02,  4.1042e-02, -2.2667e-02,\n",
       "           2.2091e-02,  4.3209e-02, -4.3479e-03,  2.9259e-02, -1.9147e-02,\n",
       "          -2.2880e-02,  2.9174e-02, -4.2775e-03,  2.2988e-02,  1.6942e-02,\n",
       "          -1.0145e-02,  1.1695e-02, -7.3655e-03, -8.5849e-03, -1.0479e-03,\n",
       "          -3.6834e-02,  1.3288e-02,  1.0557e-03, -1.3010e-02, -2.6984e-02,\n",
       "           1.1204e-02,  5.9519e-03, -2.7386e-03,  3.9582e-03,  3.3059e-02,\n",
       "          -1.3822e-02,  2.5266e-02, -1.2555e-02, -2.6695e-03, -8.0462e-03,\n",
       "           6.2693e-03, -3.8500e-02,  2.3309e-02, -1.6089e-02,  6.3824e-03,\n",
       "          -2.0204e-02,  3.1944e-02,  3.6695e-02,  1.4962e-02, -3.5523e-03,\n",
       "          -1.2950e-02,  2.4899e-03,  1.0668e-02, -1.9963e-02, -2.8234e-02,\n",
       "           4.1671e-02,  1.2029e-03, -9.5997e-04,  6.2032e-03,  5.8372e-03,\n",
       "          -1.1303e-02, -1.4569e-02, -2.3904e-02, -1.0441e-02,  5.0173e-03,\n",
       "          -4.3424e-04, -7.4022e-02, -3.6908e-02, -7.0213e-03,  1.9183e-02,\n",
       "          -3.3335e-02,  2.1199e-02,  9.7426e-03,  1.2246e-02, -2.5941e-02,\n",
       "           5.9899e-03, -9.6318e-03, -1.3856e-02,  2.5718e-02,  7.4703e-03,\n",
       "          -1.1659e-02,  2.6228e-03, -5.8726e-02,  3.9484e-03,  4.6722e-03,\n",
       "          -1.1730e-02,  7.1078e-03,  5.7750e-04, -2.1422e-02,  7.6578e-03,\n",
       "          -9.9661e-03, -2.3365e-02,  9.3345e-03, -1.3124e-03, -9.2250e-03,\n",
       "          -9.7311e-03,  1.4082e-02, -2.0491e-02, -2.3023e-02,  1.6326e-02,\n",
       "          -4.4719e-02, -1.1966e-02,  2.5343e-02,  1.1119e-02,  3.1411e-04,\n",
       "           4.0001e-03,  2.6025e-02, -5.7038e-03, -2.7984e-02, -1.1150e-02,\n",
       "          -2.0066e-02, -2.0527e-02,  2.5630e-02, -3.6335e-03, -6.3632e-03,\n",
       "          -3.4200e-02,  3.2433e-02,  7.1662e-03,  1.6293e-02,  4.0589e-02,\n",
       "          -1.1112e-02, -3.8071e-02, -2.3864e-02,  1.1760e-02, -2.7006e-04,\n",
       "           6.4461e-03, -1.8549e-02, -6.4349e-02, -2.1986e-02,  7.8649e-03,\n",
       "           3.9566e-02, -1.2118e-02, -2.5491e-02,  1.6352e-02, -7.1933e-02,\n",
       "           2.4679e-02, -1.0920e-02, -2.2560e-02,  7.1920e-03,  7.8673e-03,\n",
       "           8.9007e-03, -5.7611e-03, -3.7440e-02, -1.6615e-02,  1.1199e-02,\n",
       "           5.3891e-02, -1.8775e-02, -1.0615e-02,  6.1002e-03, -3.1612e-03,\n",
       "           2.5007e-02, -2.8349e-02, -1.2255e-03,  8.3172e-03,  6.9040e-02,\n",
       "           1.8379e-02,  4.4217e-02,  1.7442e-03, -1.8284e-02, -4.6131e-02,\n",
       "          -6.6841e-03, -2.5212e-02,  4.3351e-02,  2.6335e-02, -1.2563e-02,\n",
       "          -3.4207e-03,  1.1676e-02, -4.3692e-02,  6.1671e-05,  5.8086e-02,\n",
       "          -3.2739e-03, -3.4708e-03,  1.2075e-02, -4.3671e-03, -2.3288e-02,\n",
       "           2.0155e-02,  1.4332e-02,  6.3812e-03, -1.2380e-02,  5.4225e-02,\n",
       "          -1.6172e-02,  3.1197e-02, -4.7635e-02, -1.3393e-02, -8.7379e-03,\n",
       "           1.7838e-02, -1.8921e-02,  8.2216e-04,  2.5563e-02, -1.6134e-02,\n",
       "           1.6643e-02, -4.0764e-03,  3.0178e-02, -2.1057e-02,  8.5747e-03,\n",
       "          -1.9638e-02,  1.4002e-03, -1.9717e-02, -3.5478e-02, -2.2257e-03,\n",
       "           2.2586e-02, -9.2613e-03,  1.8408e-02, -2.6762e-02, -1.0609e-02,\n",
       "           2.1430e-02, -9.0022e-03, -3.2269e-03,  6.7032e-03,  8.3659e-03,\n",
       "          -1.5047e-02,  1.8140e-02,  3.4376e-03, -4.7598e-02, -1.4770e-02,\n",
       "           3.4380e-02, -2.6256e-02, -7.3186e-03, -8.8325e-03, -7.1570e-03,\n",
       "          -1.3241e-02, -2.7409e-02,  3.5784e-03, -7.1418e-03,  3.9739e-02,\n",
       "           1.0636e-02,  7.4650e-03,  1.6387e-02, -1.3991e-02,  2.3282e-02,\n",
       "          -1.0536e-02,  1.3904e-02,  2.3962e-02,  6.6586e-03,  3.8716e-02,\n",
       "          -1.5127e-02, -8.8517e-03,  8.7528e-03, -2.4784e-02,  3.9862e-03,\n",
       "           7.0658e-03,  8.5206e-03,  9.7438e-03,  1.7284e-02, -1.4447e-03,\n",
       "           1.2906e-02, -1.6342e-02,  2.6016e-02,  6.5024e-03, -1.5449e-02,\n",
       "           2.3745e-02,  5.6282e-03, -7.1076e-03, -1.4286e-02, -1.1406e-02,\n",
       "          -2.4112e-02, -5.3364e-03,  1.4269e-02, -1.2544e-03, -1.9027e-02,\n",
       "          -2.0050e-02, -4.1501e-03, -2.1402e-02,  2.2720e-02, -4.5994e-03,\n",
       "          -1.9284e-02, -7.1863e-03,  2.4320e-02, -4.0538e-03, -3.3978e-02,\n",
       "           2.9069e-03, -3.3256e-02,  5.2208e-02, -2.8190e-02, -6.7546e-03,\n",
       "          -2.2711e-02, -5.5475e-02, -4.4842e-02]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_l['viclip'].cache_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c9e980f-f4b5-4502-a923-0029cc441377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5681c49bf80b4154843798dd6a55a5cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d990d7fc84f64ee6b67287db163c054c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773d3623afef4d2baea71f9e51be22ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a8dd42407e446c9c5d370def2923e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d030dea21374464af305a75cbc81bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/229 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c839fd42ac48debd2aac44b8104537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m p \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(frames) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m8\u001b[39m)):\n\u001b[0;32m---> 13\u001b[0m     texts, probs \u001b[38;5;241m=\u001b[39m \u001b[43mretrieve_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mphrase\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     logits_curr\u001b[38;5;241m.\u001b[39mappend((probs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem(), i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     15\u001b[0m     p\u001b[38;5;241m.\u001b[39mappend(probs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/PycharmProjects/InternVideo/Data/InternVid/viclip/__init__.py:62\u001b[0m, in \u001b[0;36mretrieve_text\u001b[0;34m(frames, texts, models, topk, device)\u001b[0m\n\u001b[1;32m     60\u001b[0m clip \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     61\u001b[0m frames_tensor \u001b[38;5;241m=\u001b[39m frames2tensor(frames, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m---> 62\u001b[0m vid_feat \u001b[38;5;241m=\u001b[39m \u001b[43mget_vid_feat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m text_feat_d \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     65\u001b[0m text_feat_d \u001b[38;5;241m=\u001b[39m get_text_feat_dict(texts, clip, tokenizer, text_feat_d)\n",
      "File \u001b[0;32m~/PycharmProjects/InternVideo/Data/InternVid/viclip/__init__.py:25\u001b[0m, in \u001b[0;36mget_vid_feat\u001b[0;34m(frames, clip)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vid_feat\u001b[39m(frames, clip):\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vid_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/InternVideo/Data/InternVid/viclip/viclip.py:254\u001b[0m, in \u001b[0;36mViCLIP.get_vid_features\u001b[0;34m(self, input_frames)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vid_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_frames):\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 254\u001b[0m         clip_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_vision\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    255\u001b[0m         clip_feat \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m clip_feat\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clip_feat\n",
      "File \u001b[0;32m~/PycharmProjects/InternVideo/Data/InternVid/viclip/viclip.py:153\u001b[0m, in \u001b[0;36mViCLIP.encode_vision\u001b[0;34m(self, image, test)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m test \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasking_prob \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvision_encoder(\n\u001b[1;32m    150\u001b[0m         image, masking_prob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasking_prob\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvision_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/xclip/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/xclip/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/InternVideo/Data/InternVid/viclip/viclip_vision.py:190\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[0;34m(self, x, masking_prob)\u001b[0m\n\u001b[1;32m    187\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_pre(x)\n\u001b[1;32m    189\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m#BND -> NBD\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_post(x)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/xclip/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/xclip/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/InternVideo/Data/InternVid/viclip/viclip_vision.py:99\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresblocks):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_num:\n\u001b[0;32m---> 99\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m         x \u001b[38;5;241m=\u001b[39m blk(x)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/xclip/lib/python3.9/site-packages/torch/_compile.py:31\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     29\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/xclip/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:600\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m prior \u001b[38;5;241m=\u001b[39m set_eval_frame(callback)\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    602\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/xclip/lib/python3.9/site-packages/torch/utils/checkpoint.py:481\u001b[0m, in \u001b[0;36mcheckpoint\u001b[0;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m context_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m noop_context_fn \u001b[38;5;129;01mor\u001b[39;00m debug \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    478\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing `context_fn` or `debug` is only supported when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    479\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_reentrant=False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    480\u001b[0m         )\n\u001b[0;32m--> 481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckpointFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m     gen \u001b[38;5;241m=\u001b[39m _checkpoint_without_reentrant_generator(\n\u001b[1;32m    484\u001b[0m         function, preserve, context_fn, determinism_check, debug, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    485\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/xclip/lib/python3.9/site-packages/torch/autograd/function.py:574\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    573\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/xclip/lib/python3.9/site-packages/torch/utils/checkpoint.py:255\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[0;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[1;32m    252\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(\u001b[38;5;241m*\u001b[39mtensor_inputs)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 255\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mrun_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/miniconda3/envs/xclip/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/xclip/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/InternVideo/Data/InternVid/viclip/viclip_vision.py:82\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 82\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     83\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(x)))\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/PycharmProjects/InternVideo/Data/InternVid/viclip/viclip_vision.py:79\u001b[0m, in \u001b[0;36mResidualAttentionBlock.attention\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattention\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_mask\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/xclip/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/xclip/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/xclip/lib/python3.9/site-packages/torch/nn/modules/activation.py:1275\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1262\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1272\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1273\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1275\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m/opt/miniconda3/envs/xclip/lib/python3.9/site-packages/torch/nn/functional.py:5560\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5557\u001b[0m k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m   5558\u001b[0m v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m-> 5560\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5561\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(bsz \u001b[38;5;241m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m   5563\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "logits = []\n",
    "preds  = []\n",
    "for video_path, phrase, frames in tqdm(videos[:51]):\n",
    "    video = cv2.VideoCapture(os.path.join('../../../photography-model/', video_path))\n",
    "    \n",
    "    frames = [x for x in _frame_from_video(video)]\n",
    "\n",
    "    logits_curr = []\n",
    "    p = []\n",
    "    for i in tqdm(range(len(frames) - 8)):\n",
    "        texts, probs = retrieve_text(frames[i:i+8], [phrase], models=model_l, topk=1, device=\"cpu\")\n",
    "        logits_curr.append((probs[0].item(), i + 1))\n",
    "        p.append(probs[0].item())\n",
    "    logits.append(logits_curr)\n",
    "    preds.append(np.argmax(p) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6435ba40-68b2-4680-bb82-3bbd153d1420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(25), np.int64(4), np.int64(154), np.int64(135)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "688aaa41-f7ea-402f-ab38-77056c67286b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GIF100/3.mp4',\n",
       " 'A kid splashes into the water.',\n",
       " [237,\n",
       "  238,\n",
       "  239,\n",
       "  240,\n",
       "  241,\n",
       "  242,\n",
       "  243,\n",
       "  244,\n",
       "  245,\n",
       "  246,\n",
       "  247,\n",
       "  248,\n",
       "  249,\n",
       "  250,\n",
       "  251,\n",
       "  252,\n",
       "  253,\n",
       "  254,\n",
       "  255,\n",
       "  256,\n",
       "  257,\n",
       "  258,\n",
       "  259,\n",
       "  260,\n",
       "  261,\n",
       "  262,\n",
       "  263,\n",
       "  264,\n",
       "  265,\n",
       "  266,\n",
       "  267,\n",
       "  268,\n",
       "  269,\n",
       "  270,\n",
       "  271,\n",
       "  272,\n",
       "  273,\n",
       "  274,\n",
       "  276,\n",
       "  277,\n",
       "  278,\n",
       "  279,\n",
       "  280,\n",
       "  281,\n",
       "  282,\n",
       "  275,\n",
       "  283,\n",
       "  284,\n",
       "  285,\n",
       "  286,\n",
       "  287,\n",
       "  288,\n",
       "  289,\n",
       "  290,\n",
       "  291,\n",
       "  292,\n",
       "  293,\n",
       "  294,\n",
       "  295,\n",
       "  296,\n",
       "  297,\n",
       "  298,\n",
       "  299,\n",
       "  300])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7ec8bc",
   "metadata": {},
   "source": [
    "$$\\Large \\textbf{Predicting}$$\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148797b2-e778-4e21-9d08-7f0161dea0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('example1.mp4')\n",
    "frames = [x for x in _frame_from_video(video)]\n",
    "text_candidates = ['A dog jumping in snow', \"A car driving off a cliff\", \"A dog and its owner wrestle in the snowy yard, chasing each other with joyous abandon.\"]\n",
    "texts, probs = retrieve_text(frames, text_candidates, models=model_l, topk=2, device=\"cpu\")\n",
    "for t, p in list(zip(texts, probs)):\n",
    "    print(t, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaa0cbd-65d3-4174-83ae-4b47af287cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_l['viclip'].cache_txt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd5a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def predictVideo(videoPath, phrase):\n",
    "    video = cv2.VideoCapture(videoPath)\n",
    "    frames = [x for x in _frame_from_video(video)]\n",
    "    text_candidates = [phrase]\n",
    "    texts, probs = retrieve_text(frames, text_candidates, models=model_l, topk=1)\n",
    "    return probs[0]\n",
    "\n",
    "def predict(gifPath, phrase, outputDir = \"output\", output_logits = False, window_size = 8):\n",
    "    assert(window_size >= 8)\n",
    "    split_video_to_mp4(gifPath, outputDir, window_size=8)\n",
    "    \n",
    "    logits = []\n",
    "\n",
    "    output_files = os.listdir(outputDir)\n",
    "    output_files.sort(key=lambda x: int(x.split('.')[0]))\n",
    "\n",
    "    videos = list(map(lambda x: os.path.join(outputDir, x), output_files))\n",
    "\n",
    "    videoPbar = tqdm(videos)\n",
    "    for videoPath in videoPbar:\n",
    "        videoPbar.set_description(gifPath.split('/')[-1])\n",
    "        logits.append((predictVideo(videoPath, phrase), int(videoPath.split('/')[-1].split('.')[0])))\n",
    "        \n",
    "#     if window_size > 8:\n",
    "#         additional = window_size - 8\n",
    "#         avg_logits = []\n",
    "        \n",
    "# #         if window_size == 13:\n",
    "# #             for i in range(2, len(logits) - 2):\n",
    "# #                 avg_logits.append((sum([logits[x][0] for x in [i - 2, i - 1, i, i + 1, i + 2]])/5, i + 1))\n",
    "#     else:\n",
    "#         avg_logits = logits\n",
    "    \n",
    "#     logits = avg_logits\n",
    "    \n",
    "#     if output_logits:\n",
    "#         return avg_logits\n",
    "    \n",
    "    \n",
    "    logits.sort(key=lambda x: -x[0])\n",
    "    \n",
    "    final_ans = logits[0][1] # Frame index (1 start)\n",
    "    return final_ans\n",
    "\n",
    "def runPredict(files):\n",
    "    test_tqdm = tqdm(files)\n",
    "    y_pred = []\n",
    "    for test_file in test_tqdm:\n",
    "        test_tqdm.set_description('Backflip files')\n",
    "        y_pred.append(predict(test_file, 'A person performs a backflip.'))\n",
    "\n",
    "    import pickle\n",
    "    with open('y_pred.pkl', 'wb') as file:\n",
    "        pickle.dump(y_pred, file)\n",
    "    print(\"Done saving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a00b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLogits(gifPath, phrase, outputDir = \"output\"):\n",
    "    split_video_to_mp4(gifPath, outputDir, window_size=8)\n",
    "    \n",
    "    logits = []\n",
    "\n",
    "    output_files = os.listdir(outputDir)\n",
    "    output_files.sort(key=lambda x: int(x.split('.')[0]))\n",
    "\n",
    "    videos = list(map(lambda x: os.path.join(outputDir, x), output_files))\n",
    "\n",
    "    videoPbar = tqdm(videos)\n",
    "    for videoPath in videoPbar:\n",
    "        videoPbar.set_description(gifPath.split('/')[-1])\n",
    "        logits.append((predictVideo(videoPath, phrase), int(videoPath.split('/')[-1].split('.')[0])))\n",
    "        \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca81e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented = listfile('photography-model/augment')\n",
    "augmented.sort(key = lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "print(augmented[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b9d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "runPredict(augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d660b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logitsList = []\n",
    "for file in tqdm(augmented):\n",
    "    logitsList.append(getLogits(file, 'A person performs a backflip.'))\n",
    "print(logitsList)\n",
    "with open('logits.pkl', 'wb') as file:\n",
    "    pickle.dump(logitsList, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d578bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict('photography-model/augment/22.mp4', 'A person performs a backflip.', window_size=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276186cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(graph_prediction):\n",
    "    if i == max(graph_prediction):\n",
    "        print(\"Original Prediction:\",idx + 1)\n",
    "\n",
    "for idx, i in enumerate(graph_prediction_16):\n",
    "    if i == max(graph_prediction_16):\n",
    "        print(\"New Prediction:     \",idx + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3afd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_prediction_16[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17795b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x[1] for x in graph_prediction], [x[0] for x in graph_prediction])\n",
    "plt.plot([x[1] for x in graph_prediction_16], [x[0] for x in graph_prediction_16])\n",
    "plt.title(\"Sliding Window Technique\")\n",
    "\n",
    "plt.xlabel('Frame #')\n",
    "plt.ylabel('Similarity')\n",
    "plt.gca().set_position([0, 0, 1, 1])\n",
    "plt.savefig(\"output.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e34649",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"Storage/augment/24.mp4\", 'A person performs a backflip.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5116eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[1,2,3,4,5,6,7,8,9][:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b0c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "runPredict([os.path.join('Storage/augment', x) for x in os.listdir('Storage/augment')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1096e4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13580388",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug2_files = os.listdir('aug2')\n",
    "aug2_files.sort(key = lambda x: int(x.split('.')[0]))\n",
    "runPredict([os.path.join('aug2', x) for x in aug2_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520c197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Storage\n",
    "os.system('git pull')\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a45ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive('augment', 'zip', 'aug2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd44d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "import argparse\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.base import MIMEBase\n",
    "from email import encoders\n",
    "import os\n",
    "\n",
    "# Email details\n",
    "sender_email = \"qxli2@students.everettcc.edu\"\n",
    "password = \"miSTER3Man7Jig37\"\n",
    "# Email content\n",
    "\n",
    "receiver_email = \"qing.cminst@gmail.com\"\n",
    "attachment_path = \"logits.pkl\"\n",
    "\n",
    "contents = \"I'm done bro. (regular, not augmented).\"\n",
    "subject = \"Helicopter Model Update\"\n",
    "body = f\"\"\"\n",
    "<html>\n",
    "<head>\n",
    "    <style>\n",
    "        body {{\n",
    "            font-family: monospace;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "<pre>{contents}</pre>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "message = MIMEMultipart()\n",
    "message[\"From\"] = sender_email\n",
    "message[\"To\"] = receiver_email\n",
    "message[\"Subject\"] = subject\n",
    "\n",
    "message.attach(MIMEText(body, \"html\"))\n",
    "\n",
    "if attachment_path:\n",
    "    try:\n",
    "        with open(attachment_path, \"rb\") as attachment:\n",
    "            part = MIMEBase(\"application\", \"octet-stream\")\n",
    "            part.set_payload(attachment.read())\n",
    "        \n",
    "        encoders.encode_base64(part)\n",
    "        \n",
    "        part.add_header(\n",
    "            \"Content-Disposition\",\n",
    "            f\"attachment; filename= {os.path.basename(attachment_path)}\"\n",
    "        )\n",
    "        \n",
    "        message.attach(part)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to attach file: {e}\")\n",
    "\n",
    "try:\n",
    "    server = smtplib.SMTP(\"smtp.gmail.com\", 587)\n",
    "    server.starttls()\n",
    "    server.login(sender_email, password)\n",
    "\n",
    "    server.sendmail(sender_email, receiver_email, message.as_string())\n",
    "    print(\"Email sent successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Failed to send email: {e}\")\n",
    "\n",
    "finally:\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b01a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict('backflip/49.mp4', 'A person performs a backflip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59508ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict('Storage/output_video2.mp4', 'A person performs a backflip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7562575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive(\"backfliplol\", 'zip', \"backflip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c0c2bc",
   "metadata": {},
   "source": [
    "<a href=\"y_pred.pkl\">Download</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47ec712",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853fa22e-6a7e-44e1-bea2-248e480f9649",
   "metadata": {},
   "source": [
    "$$\\Large \\textbf{XCLIP testing}$$\n",
    "\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4f75067-0acb-45a5-9c9d-bf6a45063f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting av\n",
      "  Downloading av-13.0.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.4 kB)\n",
      "Downloading av-13.0.0-cp39-cp39-macosx_11_0_arm64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: av\n",
      "Successfully installed av-13.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7063464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499/500 Completed\n",
      "-------------------------\n",
      "Correct: playing harmonica\n",
      "-------------------------\n",
      "Predictions -------------\n",
      "0.7587 | playing harmonica\n",
      "0.0100 | whistling\n",
      "0.0047 | playing accordion\n",
      "0.0044 | trimming or shaving beard\n",
      "0.0040 | crying\n",
      "-------------------------\n",
      "Top 1: 0.576\n",
      "Top 5: 0.828\n"
     ]
    }
   ],
   "source": [
    "import av\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def read_video_pyav(container, indices):\n",
    "    '''\n",
    "    Decode the video with PyAV decoder.\n",
    "    Args:\n",
    "        container (`av.container.input.InputContainer`): PyAV container.\n",
    "        indices (`List[int]`): List of frame indices to decode.\n",
    "    Returns:\n",
    "        result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).\n",
    "    '''\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    start_index = indices[0]\n",
    "    end_index = indices[-1]\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i > end_index:\n",
    "            break\n",
    "        if i >= start_index and i in indices:\n",
    "            frames.append(frame)\n",
    "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n",
    "\n",
    "\n",
    "def sample_frame_indices(clip_len, frame_sample_rate, seg_len):\n",
    "    '''\n",
    "    Sample a given number of frame indices from the video.\n",
    "    Args:\n",
    "        clip_len (`int`): Total number of frames to sample.\n",
    "        frame_sample_rate (`int`): Sample every n-th frame.\n",
    "        seg_len (`int`): Maximum allowed index of sample's last frame.\n",
    "    Returns:\n",
    "        indices (`List[int]`): List of sampled frame indices\n",
    "    '''\n",
    "    converted_len = int(clip_len * frame_sample_rate)\n",
    "    end_idx = np.random.randint(converted_len, seg_len)\n",
    "    start_idx = end_idx - converted_len\n",
    "    indices = np.linspace(start_idx, end_idx, num=clip_len)\n",
    "    indices = np.clip(indices, start_idx, end_idx - 1).astype(np.int64)\n",
    "    return indices\n",
    "\n",
    "\n",
    "# video clip consists of 300 frames (10 seconds at 30 FPS)\n",
    "file_path = hf_hub_download(\n",
    "    repo_id=\"nielsr/video-demo\", filename=\"eating_spaghetti.mp4\", repo_type=\"dataset\"\n",
    ")\n",
    "container = av.open(file_path)\n",
    "\n",
    "# sample 8 frames\n",
    "indices = sample_frame_indices(clip_len=8, frame_sample_rate=1, seg_len=container.streams.video[0].frames)\n",
    "video = read_video_pyav(container, indices)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/xclip-base-patch32\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/xclip-base-patch32\")\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "top1 = 0\n",
    "top5 = 0\n",
    "total = 0\n",
    "collect_data = []\n",
    "for check in videos:\n",
    "    container = av.open(os.path.join('../../InternVideo2/multi_modality/k600/part_0/',check))\n",
    "    indices = sample_frame_indices(clip_len=8, frame_sample_rate=1, seg_len=container.streams.video[0].frames)\n",
    "    video = read_video_pyav(container, indices)\n",
    "\n",
    "    inputs = processor(\n",
    "        text=classes.tolist(),\n",
    "        videos=list(video),\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    logits_per_video = outputs.logits_per_video\n",
    "    probs = logits_per_video.softmax(dim=1)\n",
    "\n",
    "    video_label = id_label_map[check[:11]]\n",
    "    print(f\"{total}/500 Completed\")\n",
    "    print('-'*25)\n",
    "    print(\"Correct:\", video_label)\n",
    "    print('-'*25)\n",
    "    print('Predictions ' + '-'*13)\n",
    "\n",
    "    ind = np.argpartition(probs.numpy()[0], -5)[-5:]\n",
    "    top5_list = list(zip([probs[0][i] for i in ind], [classes[i] for i in ind]))\n",
    "    top5_list.sort(key = lambda x: -x[0])\n",
    "    \n",
    "    for i,v in top5_list:\n",
    "        print(f'{i:.4f}', '|', v)\n",
    "\n",
    "    texts = [top5_list[x][1] for x in range(5)]\n",
    "    if texts[0] == video_label:\n",
    "        top1 += 1\n",
    "    if video_label in texts:\n",
    "        top5 += 1\n",
    "    total += 1\n",
    "    print('-'*25)\n",
    "    print(\"Top 1:\",top1/total)\n",
    "    print(\"Top 5:\", top5/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f096ee49-eb0c-4501-978d-cec9a8656e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(video, phrase):\n",
    "    container = av.open(video) #'../../../photography-model/GIF87/1.mp4')\n",
    "    indices = list(range(8))\n",
    "    video = read_video_pyav(container, indices)\n",
    "    \n",
    "    inputs = processor(\n",
    "        text=[phrase],\n",
    "        videos=list(video),\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits_per_video = outputs.logits_per_video\n",
    "    # probs = logits_per_video.softmax(dim=1)\n",
    "    return logits_per_video[0].numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5c7ce661-8cbb-42ea-a7fc-625155eeb318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iv2_utils.iv2 import split_video_to_mp4, get_output_dir, pickle_write, pickle_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc275de-0d48-4d9d-9f03-d4f77c1bbbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gif87_dir = '../../../photography-model/GIF87/'\n",
    "\n",
    "preds = []\n",
    "logits = []\n",
    "for i in tqdm(range(1, 88)):\n",
    "    split_video_to_mp4(os.path.join(backflip_dir, f'{i}.mp4'), output_dir='output', window_size=8)\n",
    "    logit_curr = []\n",
    "    pbar = tqdm(get_output_dir('output'))\n",
    "    for clip in pbar:\n",
    "        logit_curr.append(get_score(clip, 'A person performing a backflip.'))\n",
    "        pbar.set_description(str(np.argmax(logit_curr) + 1))\n",
    "    logits.append(list(zip(logit_curr, list(range(1, len(logit_curr) + 1)))))\n",
    "    preds.append(np.argmax(logit_curr) + 1)\n",
    "    # print(np.argmax(logit_curr) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c6c7dcb4-57c5-4f49-9726-f45cd860f219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0d9b2503af44b4a33438c577c019e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4987840f6e14a39b16d0f9ca4316c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5042ee0520564f41adedb23a6fcc0d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11a3ec35ae749599c74b09aa2e37bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15e3f62626e4533b5157a080b8faea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68d250ff604416b90528209a26da7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773cc0120c66497080b4ac12b7924c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/202 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ccad6b765b417c91a87882bc17d19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40da3644396d47b3998f6580738c9aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26eda43e3c9a45b8a3ac42a13f56934f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6028dc28adce422d9c9d13eeed541432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/203 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f7e2b69e574140a1fce037fe1763fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09aee4b270a540b5b18658bce3a0cf0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0a7212e8104ba4b653d1f043312b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e7e8a27b1d4afd887d7b99635b7abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8acec76274471d83c8c94fba0ccdd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3db1ed9ce149a9a70c6fb08467c084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c07f8bd1c73426691644330cee8e901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d507999be56408ebf5daaba1f7ac5e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7953900e81eb436c90d1b91ae53a4612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192a949d97674339877c97bb4fd2f7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306426ca001d411297086efc8a317741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b6e4f502f34b8b960e563a4923b0f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631f40f66f8140099b6d0e091f6a2f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555bff2ff1ac4cf79c8bc22a012c7569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c443e3866434b369afbccba72e87d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273cb3e1b1b542258a2f9e241d738556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb853eff1794422b9baacd4e3f1aafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f5dc23b2954db58091b8ed8aa31ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0067ee74a8840ad8bc1281bc98a1b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a4773f9f554c0b844d76a0b2e2f814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613adc61eba14d348f98a4a0dcc0f9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e73351c333644858d46a66d0e51ae20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3728c2dba6c843c3bc6282c38ab52677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8427518fd34663a38370b37cf6832e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4786c186e343a8b708f7bd2febb027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3773149b734be3b24c3a6873883522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f41023912a448090d3c5a2995641cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf76f3af6c3409e905470b348750a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5d54f27aef40089bb7be35be338f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b77346d1ca4905af9b7ffd7660312f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1eeb081e8644fd9c4cf620e801db5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f81a25ba264721818d77cf559593bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdaa15d4c93a4e25a7884ecbb811f4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ce8e7637664482815fe70b306fd697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d71b34b2e614b489f70f40f0fb68516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70d4dffd75341cb9538521c1403082a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae53fe8841dc4a0098e2f623d132e3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/143 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac122b7905bd46f6be1602ada118217b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb784f000a1478d9c6db4130dab2b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2759d040b4f848b3bc97efe7d0f8663e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "backflip_dir = '../../../photography-model/backflip/'\n",
    "\n",
    "preds = []\n",
    "logits = []\n",
    "for i in tqdm(range(1, 51)):\n",
    "    split_video_to_mp4(os.path.join(backflip_dir, f'{i}.mp4'), output_dir='output', window_size=8)\n",
    "    logit_curr = []\n",
    "    pbar = tqdm(get_output_dir('output'))\n",
    "    for clip in pbar:\n",
    "        logit_curr.append(get_score(clip, 'A person performing a backflip.'))\n",
    "        pbar.set_description(str(np.argmax(logit_curr) + 1))\n",
    "    logits.append(list(zip(logit_curr, list(range(1, len(logit_curr) + 1)))))\n",
    "    preds.append(np.argmax(logit_curr) + 1)\n",
    "    # print(np.argmax(logit_curr) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "569f0afe-4f81-4990-b914-8524ca309df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_write(preds, 'XCLIP-r8.pkl')\n",
    "pickle_write(logits, 'XCLIP-logits-r.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6250c03e-66a3-4904-a6bf-47c7e0663dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showFrames(path, highlight=False):\n",
    "    global current_pick\n",
    "    video_path = path\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    frames = []\n",
    "    success, frame = cap.read()\n",
    "    while success:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(frame)\n",
    "        frames.append(img)\n",
    "        success, frame = cap.read()\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "    if not frames:\n",
    "        print(\"No frames found in the video.\")\n",
    "        return\n",
    "    \n",
    "    root = tk.Tk()\n",
    "    root.title(path)\n",
    "    currIdx = -1\n",
    "\n",
    "    frame_anno = []\n",
    "    def display_frame(index):\n",
    "        global currIdx\n",
    "        frame_label.config(text=f\"Frame {index}\", fg = 'black' if index + 1 not in frame_anno else 'green')\n",
    "        img = ImageTk.PhotoImage(frames[index])\n",
    "        frame_canvas.create_image(0, 0, anchor=tk.NW, image=img)\n",
    "        frame_canvas.image = img\n",
    "        currIdx = index\n",
    "    \n",
    "    frame_label = tk.Label(root, text=\"Frame 0\", font=('Hack', 14), fg=\"red\" if highlight else \"black\")\n",
    "    frame_label.pack()\n",
    "    \n",
    "    frame_canvas = tk.Canvas(root, width=frames[0].width, height=frames[0].height)\n",
    "    frame_canvas.pack()\n",
    "    \n",
    "    display_frame(0)\n",
    "    \n",
    "    filename_entry = tk.Entry(root, font=('Hack', 12))\n",
    "    filename_entry.pack(pady=10)\n",
    "\n",
    "    def next_frame(event):\n",
    "        current_frame = int(frame_label.cget(\"text\").split()[1])\n",
    "        next_index = (current_frame + 1) % len(frames)\n",
    "        display_frame(next_index)\n",
    "\n",
    "    def doubleSkip(event):\n",
    "        next_frame(event)\n",
    "        next_frame(event)\n",
    "    \n",
    "    def prev_frame(event):\n",
    "        current_frame = int(frame_label.cget(\"text\").split()[1])\n",
    "        next_index = (current_frame - 1) % len(frames)\n",
    "        display_frame(next_index)\n",
    "\n",
    "    def doublePrev(event):\n",
    "        prev_frame(event)\n",
    "        prev_frame(event)\n",
    "\n",
    "    def restart(event):\n",
    "        if anno_stock100[-1][0] == path:\n",
    "            anno_stock100.pop(-1)\n",
    "            frame_anno = []\n",
    "            print(\"Removed previous one and reset frame_anno\")\n",
    "            print(anno_stock100)\n",
    "        else:\n",
    "            print(\"Not same path, ignoring\")\n",
    "    \n",
    "    def save_frame(event):\n",
    "        global currIdx\n",
    "        global anno_stock100\n",
    "\n",
    "        phrase = filename_entry.get()  # Get the text from the entry box\n",
    "        anno_stock100.append((path, phrase, frame_anno))\n",
    "        print(\"Saved!!\")\n",
    "        print(anno_stock100)\n",
    "    def add_frame(event):\n",
    "        global currIdx\n",
    "        if currIdx + 1 in frame_anno:\n",
    "            frame_anno.remove(currIdx + 1)\n",
    "            print(\"Removed\",currIdx + 1,\"as a correct frame.\")\n",
    "            display_frame(currIdx)\n",
    "        else:\n",
    "            frame_anno.append(currIdx + 1)\n",
    "            print(\"Added\", currIdx + 1, \"as a correct frame.\")\n",
    "            display_frame(currIdx)\n",
    "    \n",
    "    root.bind('<Right>', next_frame)\n",
    "    root.bind('<Left>', prev_frame)\n",
    "    root.bind('<Up>', doubleSkip)\n",
    "    root.bind('<Down>', doublePrev)\n",
    "    root.bind('<Command-s>', save_frame)\n",
    "    root.bind('<Command-f>', add_frame)\n",
    "    root.bind('<Command-r>', restart)\n",
    "    \n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73a7d7e8-ef2a-4e22-ba7b-b9daf9e16e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GIF100/46.mp4', [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = pickle_read('../../../photography-model/rustyjar/STOCK100-testing.pkl')\n",
    "video[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64645c8a-3151-4b7c-adf2-298893076875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.4.1\n",
      "CLIP Models: ['RN50', 'RN101', 'RN50x4', 'RN50x16', 'RN50x64', 'ViT-B/32', 'ViT-B/16', 'ViT-L/14', 'ViT-L/14@336px']\n"
     ]
    }
   ],
   "source": [
    "from pkg_resources import packaging\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import IPython.display\n",
    "from os import system\n",
    "from PIL import Image, ImageTk\n",
    "import urllib.request\n",
    "import tkinter as tk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import skimage\n",
    "import pickle\n",
    "import torch\n",
    "import time\n",
    "import math\n",
    "import clip\n",
    "import cv2\n",
    "import os\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CLIP Models:\",clip.available_models())\n",
    "\n",
    "def pickle_read(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def pickle_write(a, b):\n",
    "    pickle_filename = a if len(a) >= 4 and a[-4:] == \".pkl\" else b\n",
    "    data = b if pickle_filename == a else a\n",
    "    with open(pickle_filename, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "showFrames('../../../photography-model/GIF100/27.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af2b381-040e-4e36-954e-083800ba3d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "modelId": 118115,
     "modelInstanceId": 93904,
     "sourceId": 112034,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
